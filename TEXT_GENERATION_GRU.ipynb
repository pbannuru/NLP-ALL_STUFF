{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUWtA8hb2vo8HILehR6ahb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pbannuru/NLP-ALL_STUFF/blob/main/TEXT_GENERATION_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FP4biWXnDD1A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7ZT-H7rDGl1",
        "outputId": "c2486b5a-5812-4859-a7fd-68ad2657b9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n"
      ],
      "metadata": {
        "id": "ztJZglwCDN9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import time\n"
      ],
      "metadata": {
        "id": "wfAmyRqZDT6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"data\",exist_ok=True)"
      ],
      "metadata": {
        "id": "GA8spwxxDT9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !curl https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt >\"./data/shakespeare.txt\""
      ],
      "metadata": {
        "id": "jWCGdAyVDUBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt >\"./pandas.pdf\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kakky-aoKtdh",
        "outputId": "a046b333-e108-48cc-d46d-cce752f8f0c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 1089k  100 1089k    0     0  46.2M      0 --:--:-- --:--:-- --:--:-- 46.2M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    path_to_file = os.path.join(\"data\",\"shakespeare.txt\")\n",
        "    seq_length = 100  # max seq to process\n",
        "    \n",
        "    Batch_size =64   # \n",
        "    Buffer_size = 10000 # keep data in ram , while training randomly pick data from (buffer size) storage\n",
        "                                \n",
        "    embedding_dim = 256                            \n",
        "    rnn_units = 1024    # we are using 1024 GRU here, GRU is a RNN technique                    \n",
        "    EPOCHS = 30                            \n",
        "    checkpoint_dir = \"./training_ckpt\"         # storing temp model                    \n",
        "                                \n",
        "     "
      ],
      "metadata": {
        "id": "X3CfGaVrDUJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tDx4PGF7Ksa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(Config.path_to_file,'rb').read()\n",
        "text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELDqjFjiDUNz",
        "outputId": "afb2e5fb-9195-4023-dcd4-aaae5b51c1a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(Config.path_to_file,'rb').read().decode(encoding='utf-8')\n",
        "text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hB0Sc0W-DN_z",
        "outputId": "794f19fd-6d04-45dc-95b4-1562326af605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(Config.path_to_file) as f:\n",
        "    t=f.read()"
      ],
      "metadata": {
        "id": "ivEyaRzmDOCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "UEjRLNnyDOE8",
        "outputId": "c2a9c95d-d289-4dca-dd3c-7835b11eefb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUGOOdRkDOHV",
        "outputId": "a1d6c151-7709-4ca2-c919-1b5189ef03f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '$',\n",
              " '&',\n",
              " \"'\",\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '3',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))\n",
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX86hjBFDOKQ",
        "outputId": "60d60a34-cb5b-465b-bbfd-68077386bf8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorise the text\n",
        "\n",
        "char2idx = {uniChar:idx for idx,uniChar in enumerate(vocab)}\n",
        "char2idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl09kqyPDOM0",
        "outputId": "c611d254-2ea1-4251-f7de-3958fba9329f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '$': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " ',': 6,\n",
              " '-': 7,\n",
              " '.': 8,\n",
              " '3': 9,\n",
              " ':': 10,\n",
              " ';': 11,\n",
              " '?': 12,\n",
              " 'A': 13,\n",
              " 'B': 14,\n",
              " 'C': 15,\n",
              " 'D': 16,\n",
              " 'E': 17,\n",
              " 'F': 18,\n",
              " 'G': 19,\n",
              " 'H': 20,\n",
              " 'I': 21,\n",
              " 'J': 22,\n",
              " 'K': 23,\n",
              " 'L': 24,\n",
              " 'M': 25,\n",
              " 'N': 26,\n",
              " 'O': 27,\n",
              " 'P': 28,\n",
              " 'Q': 29,\n",
              " 'R': 30,\n",
              " 'S': 31,\n",
              " 'T': 32,\n",
              " 'U': 33,\n",
              " 'V': 34,\n",
              " 'W': 35,\n",
              " 'X': 36,\n",
              " 'Y': 37,\n",
              " 'Z': 38,\n",
              " 'a': 39,\n",
              " 'b': 40,\n",
              " 'c': 41,\n",
              " 'd': 42,\n",
              " 'e': 43,\n",
              " 'f': 44,\n",
              " 'g': 45,\n",
              " 'h': 46,\n",
              " 'i': 47,\n",
              " 'j': 48,\n",
              " 'k': 49,\n",
              " 'l': 50,\n",
              " 'm': 51,\n",
              " 'n': 52,\n",
              " 'o': 53,\n",
              " 'p': 54,\n",
              " 'q': 55,\n",
              " 'r': 56,\n",
              " 's': 57,\n",
              " 't': 58,\n",
              " 'u': 59,\n",
              " 'v': 60,\n",
              " 'w': 61,\n",
              " 'x': 62,\n",
              " 'y': 63,\n",
              " 'z': 64}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_as_int = np.array([char2idx[c] for c in text])\n",
        "text_as_int"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VLPhLANDOPX",
        "outputId": "1c0b803d-0b6b-4c85-9008-802bd6e260ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18, 47, 56, ..., 45,  8,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for c in text[:50] :\n",
        "    print (c,end='')\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIVdjoG9DOSI",
        "outputId": "91f8a532-f168-431e-c56c-8f6a766fb4fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for c in text[:50] :\n",
        "    print(char2idx[c],',',end='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qBCszmSDOUx",
        "outputId": "312d7994-cbe4-460e-d60c-08e7f2de14ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18 ,47 ,56 ,57 ,58 ,1 ,15 ,47 ,58 ,47 ,64 ,43 ,52 ,10 ,0 ,14 ,43 ,44 ,53 ,56 ,43 ,1 ,61 ,43 ,1 ,54 ,56 ,53 ,41 ,43 ,43 ,42 ,1 ,39 ,52 ,63 ,1 ,44 ,59 ,56 ,58 ,46 ,43 ,56 ,6 ,1 ,46 ,43 ,39 ,56 ,"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[:13],text_as_int[:13]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVFopnSyDOXW",
        "outputId": "97c1f179-0940-4199-9a98-a3bc81e8d916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('First Citizen', array([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples_per_epoch = len(text)//(Config.seq_length +1)   # max length we are going to process\n",
        "examples_per_epoch                                    # +1 here is Ex: hello = 4+1 hell is input and ouput = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtGhvBTQDOaG",
        "outputId": "dfb90bac-9263-463d-ac35-be0efeaec438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11043"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx2char = {val:key for key,val in char2idx.items()}\n"
      ],
      "metadata": {
        "id": "DLWYKx2mDOdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)   # creatig training examples\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "    print(idx2char[i.numpy()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrHWAuUSDOfJ",
        "outputId": "921e7d4f-b0c7-4f12-cefa-d02213538e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = char_dataset.batch(Config.seq_length+1,drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "    print(item.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_eWmFfhDOhx",
        "outputId": "7aec82f7-8518-448e-f581-28c04f2466b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
            "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
            " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
            "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
            "  0 37 53 59  1]\n",
            "[39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1\n",
            " 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0\n",
            " 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8\n",
            "  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1\n",
            " 63 53 59  1 49]\n",
            "[52 53 61  1 15 39 47 59 57  1 25 39 56 41 47 59 57  1 47 57  1 41 46 47\n",
            " 43 44  1 43 52 43 51 63  1 58 53  1 58 46 43  1 54 43 53 54 50 43  8  0\n",
            "  0 13 50 50 10  0 35 43  1 49 52 53 61  5 58  6  1 61 43  1 49 52 53 61\n",
            "  5 58  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 24 43 58  1\n",
            " 59 57  1 49 47]\n",
            "[50 50  1 46 47 51  6  1 39 52 42  1 61 43  5 50 50  1 46 39 60 43  1 41\n",
            " 53 56 52  1 39 58  1 53 59 56  1 53 61 52  1 54 56 47 41 43  8  0 21 57\n",
            "  5 58  1 39  1 60 43 56 42 47 41 58 12  0  0 13 50 50 10  0 26 53  1 51\n",
            " 53 56 43  1 58 39 50 49 47 52 45  1 53 52  5 58 11  1 50 43 58  1 47 58\n",
            "  1 40 43  1 42]\n",
            "[53 52 43 10  1 39 61 39 63  6  1 39 61 39 63  2  0  0 31 43 41 53 52 42\n",
            "  1 15 47 58 47 64 43 52 10  0 27 52 43  1 61 53 56 42  6  1 45 53 53 42\n",
            "  1 41 47 58 47 64 43 52 57  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43\n",
            " 52 10  0 35 43  1 39 56 43  1 39 41 41 53 59 52 58 43 42  1 54 53 53 56\n",
            "  1 41 47 58 47]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in sequences.take(5):\n",
        "    print(\"\".join([idx2char[c] for c in item.numpy()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgV2VcA7DOkI",
        "outputId": "e5cb8ab0-f6f3-428f-e2aa-35d5b6c48655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n",
            "now Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us ki\n",
            "ll him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be d\n",
            "one: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text,target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "_M4BmVUREPcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example,target_example in dataset.take(1):\n",
        "    print(\"input_data:\\n\")\n",
        "    print(\"\".join([idx2char[i] for i in input_example.numpy()]))\n",
        "    print(\"target_data:\\n\")\n",
        "   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JTmmjQtEPfF",
        "outputId": "0fcee951-aa1a-42ea-843d-386acf82bae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_data:\n",
            "\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "target_data:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating training batches\n",
        "\n",
        "dataset = dataset.shuffle(Config.Buffer_size).batch(Config.Batch_size,drop_remainder=True)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0XWcozjEPhn",
        "outputId": "26f39f42-66dc-4e15-8360-35f0a0dd164a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Config.vocab_size = len(vocab)"
      ],
      "metadata": {
        "id": "l5bXamKaEPkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size,embedding_dim,rnn_units,batch_size):\n",
        "    model= tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size,embedding_dim,batch_input_shape=[batch_size,None]),\n",
        "        tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,    #no output is given by each GRU\n",
        "                            stateful=True,            # for one epoch to next one hidden state =0,means False,for next epoch it starts with zero so it take chunk of data and predict but if it is TRUE it memorise whole para and gives result.\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    \n",
        "    \n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "p6wAfeu1EPmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(\n",
        "    vocab_size=Config.vocab_size,\n",
        "    embedding_dim=Config.embedding_dim,\n",
        "    rnn_units=Config.rnn_units,\n",
        "    batch_size = Config.Batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "b19O1MALEPo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(Labels,Logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(Labels,Logits,from_logits=True)"
      ],
      "metadata": {
        "id": "w9rFdUkcEPrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss=loss)"
      ],
      "metadata": {
        "id": "M5yyeZsvEPtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_prefix = os.path.join(Config.checkpoint_dir,\"ckpt_{epoch}\")\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True\n",
        ")"
      ],
      "metadata": {
        "id": "BzxEIgmGEPxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset,epochs = Config.EPOCHS,callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGigKf5QEPzQ",
        "outputId": "414734b5-8a69-4c87-c55a-825d78db16da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "172/172 [==============================] - 16s 52ms/step - loss: 2.6815\n",
            "Epoch 2/30\n",
            "172/172 [==============================] - 10s 52ms/step - loss: 1.9514\n",
            "Epoch 3/30\n",
            "172/172 [==============================] - 10s 52ms/step - loss: 1.6825\n",
            "Epoch 4/30\n",
            "172/172 [==============================] - 10s 53ms/step - loss: 1.5370\n",
            "Epoch 5/30\n",
            "172/172 [==============================] - 10s 53ms/step - loss: 1.4496\n",
            "Epoch 6/30\n",
            "172/172 [==============================] - 10s 54ms/step - loss: 1.3892\n",
            "Epoch 7/30\n",
            "172/172 [==============================] - 10s 54ms/step - loss: 1.3431\n",
            "Epoch 8/30\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.3050\n",
            "Epoch 9/30\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.2696\n",
            "Epoch 10/30\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.2371\n",
            "Epoch 11/30\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.2049\n",
            "Epoch 12/30\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.1727\n",
            "Epoch 13/30\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.1412\n",
            "Epoch 14/30\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.1068\n",
            "Epoch 15/30\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.0729\n",
            "Epoch 16/30\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.0386\n",
            "Epoch 17/30\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.0021\n",
            "Epoch 18/30\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 0.9665\n",
            "Epoch 19/30\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.9326\n",
            "Epoch 20/30\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.8999\n",
            "Epoch 21/30\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.8682\n",
            "Epoch 22/30\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 0.8383\n",
            "Epoch 23/30\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 0.8126\n",
            "Epoch 24/30\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.7890\n",
            "Epoch 25/30\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.7688\n",
            "Epoch 26/30\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.7485\n",
            "Epoch 27/30\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 0.7329\n",
            "Epoch 28/30\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 0.7200\n",
            "Epoch 29/30\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 0.7075\n",
            "Epoch 30/30\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 0.6959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(len(text)/Config.Batch_size)/(Config.seq_length+1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DKs55UiDOmV",
        "outputId": "22d60be5-51f4-433e-c8cc-6a3efd679baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "172.55476485148515"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Config.seq_length"
      ],
      "metadata": {
        "id": "5PdxbaKmGS9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d90f8864-9ec9-4cc2-fe46-952892aef545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# restoring checkpoint:\n",
        "\n",
        "tf.train.latest_checkpoint(Config.checkpoint_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "YxHXPsjqEsbD",
        "outputId": "365f5e33-3a75-4160-f4e6-7cc168f3de92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_ckpt/ckpt_30'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_from_ckpt = build_model(\n",
        "    vocab_size=Config.vocab_size,\n",
        "    embedding_dim=Config.embedding_dim,\n",
        "    rnn_units=Config.rnn_units,\n",
        "    batch_size = 1\n",
        ")"
      ],
      "metadata": {
        "id": "sW8uE6-mEsd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_from_ckpt.load_weights(tf.train.latest_checkpoint(Config.checkpoint_dir))\n",
        "\n",
        "model_from_ckpt.build(tf.TensorShape)"
      ],
      "metadata": {
        "id": "J9LHJYX8EsgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_from_ckpt.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzWflWCnEsi0",
        "outputId": "2764897c-c840-455e-fdd4-a6f869bf2aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (1, None, 256)            16640     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (1, None, 1024)           3938304   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, None, 65)             66625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_from_ckpt.summary() # batch size given 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4EBBGiTEslE",
        "outputId": "1064dea4-a976-4153-dc13-239a56bb4d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (1, None, 256)            16640     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (1, None, 1024)           3938304   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, None, 65)             66625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction\n",
        "def generate_text(model,start_string,no_of_chars_to_gen =1000):\n",
        "  input_val = [char2idx[s] for s in start_string] # text converted to int\n",
        "  input_val = tf.expand_dims(input_val,0) # [] --> [1,]  1D to 2D\n",
        "\n",
        "  text_generated = list()\n",
        "\n",
        "  temperature = 1.0  # kind of normalisation to the prediction\n",
        "  model.reset_states() # resetting the previous status of training\n",
        "  for i in range(no_of_chars_to_gen):\n",
        "    predictions = model(input_val)\n",
        "\n",
        "    predictions=tf.squeeze(predictions,0)\n",
        "\n",
        "    predictions=predictions / temperature\n",
        "\n",
        "    #print(predictions)\n",
        "\n",
        "    predicted_id= tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    input_val=tf.expand_dims([predicted_id],0)\n",
        "\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return start_string +\"\".join(text_generated)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zk6eBvhvEsnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = generate_text(model=model_from_ckpt,start_string=\"pavan kumar\",no_of_chars_to_gen=1000)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Fpi5-ZOMZKc",
        "outputId": "1a63aced-8390-400d-aa4c-fa1d2422da41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pavan kumark;\n",
            "And, if we be, the shore of heaven:\n",
            "I would be another for't; commanded there\n",
            "And smooth the truth:\n",
            "'Tis thoughts to see 'em!--\n",
            "The mather will I learn the rootman bad as true?\n",
            "Jointed all, that feed's incress and account,\n",
            "Show thy descriet, and save yourself spoke\n",
            "Fox our affaits of heads er passing path\n",
            "Thy by the rosem prison.\n",
            "\n",
            "CORIOLANUS:\n",
            "Do, get thee to our tento, time\n",
            "The flours of hell, and broke her thanks.\n",
            "\n",
            "ABHORSON:\n",
            "Lo, canst thou gave this blood there is no cause to stand, to Angelo were butcher'd, O, that I regreet\n",
            "The patricians of you soundly kind\n",
            "secution, and seventeties and danger that wine enemies\n",
            "Of gracious Richard, England's king but Edward?\n",
            "He was not yet behind in Padua. Dran, sir: sir!\n",
            "\n",
            "AUTOLYCUS:\n",
            "Away, away, begranato, there show'd me and\n",
            "Self-whine and all, of late,\n",
            "Which are heaven with bother's Chert is sich and heart\n",
            "To have asher state and marriage, have accounted\n",
            "I throne; the hearers will acquaint\n",
            "My plain your sight as you had then to lount:\n",
            "All thin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eNuPoNzwEsu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "92Cn4RuOEsxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "clOPeNn1Eszv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "API0VA6IEs2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Dxxz-JeEs40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ce6K8fTvEs7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5g0OAfdiEs97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JfVyv4LHEtAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OzPMAlDEEtCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7MEjQJeiEtFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gK5VKpRCEtIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x8T_j7MYEtKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0XNUk8S8EtMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9wxPtMQgEtOj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}